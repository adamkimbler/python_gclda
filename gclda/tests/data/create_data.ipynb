{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create test files\n",
    "Need:\n",
    "- 10 articles with permission, 5 arbitrary features\n",
    "- abstracts.csv\n",
    "- feature_counts.txt\n",
    "- neurosynth_dataset.pkl\n",
    "    - This means creating reduced versions of **database.txt** and **features.txt**\n",
    "- dataset_files/pmids.txt\n",
    "- dataset_files/peak_indices.txt\n",
    "- dataset_files/word_labels.txt\n",
    "- dataset_files/word_indices.txt\n",
    "- gclda_dataset.pkl\n",
    "- gclda_model.pkl\n",
    "\n",
    "Have: \n",
    "- continuous.nii.gz\n",
    "- roi.nii.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import neurosynth\n",
    "from gclda.dataset import Dataset\n",
    "from gclda.dataset import import_neurosynth\n",
    "from gclda.tests.utils import get_test_data_path\n",
    "from gclda.model import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Constants\n",
    "in_dir = '/Users/tsalo/Desktop/ns-dataset/'\n",
    "out_dir = get_test_data_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "db_file = join(in_dir, 'database.txt')\n",
    "feat_file = join(in_dir, 'features.txt')\n",
    "df_db = pd.read_csv(db_file, sep='\\t', index_col='id')\n",
    "df_feat = pd.read_csv(feat_file, sep='\\t', index_col='pmid')\n",
    "pmids = df_db.index.unique()[:10]\n",
    "features = ['addition', 'analyzed', 'anterior', 'blood', 'conditions']\n",
    "df_db = df_db.loc[pmids]\n",
    "df_feat = df_feat.loc[pmids][features]\n",
    "df_db.to_csv(join(in_dir, 'database_reduced.txt'), sep='\\t',\n",
    "             index_label='id')\n",
    "df_feat.to_csv(join(in_dir, 'features_reduced.txt'), sep='\\t',\n",
    "               index_label='pmid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Neurosynth dataset\n",
    "dataset = neurosynth.Dataset(join(in_dir, 'database_reduced.txt'),\n",
    "                             join(in_dir, 'features_reduced.txt'))\n",
    "dataset.save(join(out_dir, 'neurosynth_dataset.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Counts file\n",
    "counts_file = join(out_dir, 'feature_counts.txt')\n",
    "dat = df_feat.values\n",
    "dat[dat>0] = 1\n",
    "dat = dat.astype(int)\n",
    "df_counts = pd.DataFrame(columns=df_feat.columns, index=df_feat.index, data=dat)\n",
    "df_counts.to_csv(counts_file, sep='\\t', index_label='pmid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pmid</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9065511</th>\n",
       "      <td>test analyzed conditions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9084599</th>\n",
       "      <td>test anterior conditions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9114263</th>\n",
       "      <td>test addition analyzed anterior blood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9185551</th>\n",
       "      <td>test anterior blood conditions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9256495</th>\n",
       "      <td>test conditions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9391021</th>\n",
       "      <td>test blood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9405692</th>\n",
       "      <td>test addition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9412517</th>\n",
       "      <td>test addition blood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9465007</th>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9491989</th>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      abstract\n",
       "pmid                                          \n",
       "9065511               test analyzed conditions\n",
       "9084599               test anterior conditions\n",
       "9114263  test addition analyzed anterior blood\n",
       "9185551         test anterior blood conditions\n",
       "9256495                        test conditions\n",
       "9391021                             test blood\n",
       "9405692                          test addition\n",
       "9412517                    test addition blood\n",
       "9465007                                   test\n",
       "9491989                                   test"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Abstracts file\n",
    "abstracts = []\n",
    "for i in range(df_counts.shape[0]):\n",
    "    row = df_counts.iloc[i]\n",
    "    string = 'test ' + ' '.join(row[row==1].index.values)\n",
    "    string = string.strip()\n",
    "    abstracts.append(string)\n",
    "df_abstracts = pd.DataFrame(index=df_counts.index, columns=['abstract'],\n",
    "                            data=abstracts)\n",
    "df_abstracts.to_csv(join(out_dir, 'abstracts.csv'), index_label='pmid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ns_dset_file = join(out_dir, 'neurosynth_dataset.pkl')\n",
    "temp_dir = join(out_dir, 'temp')\n",
    "\n",
    "ns_dset = neurosynth.Dataset.load(ns_dset_file)\n",
    "import_neurosynth(ns_dset, 'dataset_files', out_dir=out_dir,\n",
    "                  counts_file=counts_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = Dataset('dataset_files', out_dir)\n",
    "dataset.save(join(out_dir, 'gclda_dataset.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing GC-LDA Model\n",
      "Initializing GC-LDA Model\n",
      "Iter 0001: Sampling z\n",
      "Iter 0001: Sampling y|r\n",
      "Iter 0001: Updating spatial params\n",
      "Iter 0001: Computing log-likelihood\n",
      "Iter 0001 Log-likely: x =   -11991.7, w =      -27.5, tot =   -12019.2\n",
      "Iter 0002: Sampling z\n",
      "Iter 0002: Sampling y|r\n",
      "Iter 0002: Updating spatial params\n",
      "Iter 0002: Computing log-likelihood\n",
      "Iter 0002 Log-likely: x =   -12012.0, w =      -29.0, tot =   -12041.0\n",
      "Iter 0003: Sampling z\n",
      "Iter 0003: Sampling y|r\n",
      "Iter 0003: Updating spatial params\n",
      "Iter 0003: Computing log-likelihood\n",
      "Iter 0003 Log-likely: x =   -12064.6, w =      -29.2, tot =   -12093.9\n",
      "Iter 0004: Sampling z\n",
      "Iter 0004: Sampling y|r\n",
      "Iter 0004: Updating spatial params\n",
      "Iter 0004: Computing log-likelihood\n",
      "Iter 0004 Log-likely: x =   -12148.8, w =      -34.4, tot =   -12183.2\n",
      "Iter 0005: Sampling z\n",
      "Iter 0005: Sampling y|r\n",
      "Iter 0005: Updating spatial params\n",
      "Iter 0005: Computing log-likelihood\n",
      "Iter 0005 Log-likely: x =   -12361.4, w =      -37.9, tot =   -12399.4\n",
      "Iter 0006: Sampling z\n",
      "Iter 0006: Sampling y|r\n",
      "Iter 0006: Updating spatial params\n",
      "Iter 0006: Computing log-likelihood\n",
      "Iter 0006 Log-likely: x =   -12334.9, w =      -34.9, tot =   -12369.8\n",
      "Iter 0007: Sampling z\n",
      "Iter 0007: Sampling y|r\n",
      "Iter 0007: Updating spatial params\n",
      "Iter 0007: Computing log-likelihood\n",
      "Iter 0007 Log-likely: x =   -12161.7, w =      -34.1, tot =   -12195.8\n",
      "Iter 0008: Sampling z\n",
      "Iter 0008: Sampling y|r\n",
      "Iter 0008: Updating spatial params\n",
      "Iter 0008: Computing log-likelihood\n",
      "Iter 0008 Log-likely: x =   -12128.9, w =      -30.2, tot =   -12159.1\n",
      "Iter 0009: Sampling z\n",
      "Iter 0009: Sampling y|r\n",
      "Iter 0009: Updating spatial params\n",
      "Iter 0009: Computing log-likelihood\n",
      "Iter 0009 Log-likely: x =   -12155.7, w =      -25.7, tot =   -12181.4\n",
      "Iter 0010: Sampling z\n",
      "Iter 0010: Sampling y|r\n",
      "Iter 0010: Updating spatial params\n",
      "Iter 0010: Computing log-likelihood\n",
      "Iter 0010 Log-likely: x =   -12186.4, w =      -26.8, tot =   -12213.2\n",
      "Iter 0011: Sampling z\n",
      "Iter 0011: Sampling y|r\n",
      "Iter 0011: Updating spatial params\n",
      "Iter 0011: Computing log-likelihood\n",
      "Iter 0011 Log-likely: x =   -12099.7, w =      -26.7, tot =   -12126.5\n",
      "Iter 0012: Sampling z\n",
      "Iter 0012: Sampling y|r\n",
      "Iter 0012: Updating spatial params\n",
      "Iter 0012: Computing log-likelihood\n",
      "Iter 0012 Log-likely: x =   -12061.8, w =      -26.3, tot =   -12088.0\n",
      "Iter 0013: Sampling z\n",
      "Iter 0013: Sampling y|r\n",
      "Iter 0013: Updating spatial params\n",
      "Iter 0013: Computing log-likelihood\n",
      "Iter 0013 Log-likely: x =   -12101.6, w =      -27.3, tot =   -12128.9\n",
      "Iter 0014: Sampling z\n",
      "Iter 0014: Sampling y|r\n",
      "Iter 0014: Updating spatial params\n",
      "Iter 0014: Computing log-likelihood\n",
      "Iter 0014 Log-likely: x =   -12081.9, w =      -26.6, tot =   -12108.5\n",
      "Iter 0015: Sampling z\n",
      "Iter 0015: Sampling y|r\n",
      "Iter 0015: Updating spatial params\n",
      "Iter 0015: Computing log-likelihood\n",
      "Iter 0015 Log-likely: x =   -12140.9, w =      -25.9, tot =   -12166.9\n",
      "Iter 0016: Sampling z\n",
      "Iter 0016: Sampling y|r\n",
      "Iter 0016: Updating spatial params\n",
      "Iter 0016: Computing log-likelihood\n",
      "Iter 0016 Log-likely: x =   -12073.6, w =      -25.2, tot =   -12098.7\n",
      "Iter 0017: Sampling z\n",
      "Iter 0017: Sampling y|r\n",
      "Iter 0017: Updating spatial params\n",
      "Iter 0017: Computing log-likelihood\n",
      "Iter 0017 Log-likely: x =   -12107.1, w =      -25.3, tot =   -12132.4\n",
      "Iter 0018: Sampling z\n",
      "Iter 0018: Sampling y|r\n",
      "Iter 0018: Updating spatial params\n",
      "Iter 0018: Computing log-likelihood\n",
      "Iter 0018 Log-likely: x =   -12038.1, w =      -26.3, tot =   -12064.4\n",
      "Iter 0019: Sampling z\n",
      "Iter 0019: Sampling y|r\n",
      "Iter 0019: Updating spatial params\n",
      "Iter 0019: Computing log-likelihood\n",
      "Iter 0019 Log-likely: x =   -12017.9, w =      -27.9, tot =   -12045.9\n",
      "Iter 0020: Sampling z\n",
      "Iter 0020: Sampling y|r\n",
      "Iter 0020: Updating spatial params\n",
      "Iter 0020: Computing log-likelihood\n",
      "Iter 0020 Log-likely: x =   -12026.5, w =      -29.5, tot =   -12056.0\n",
      "Iter 0021: Sampling z\n",
      "Iter 0021: Sampling y|r\n",
      "Iter 0021: Updating spatial params\n",
      "Iter 0021: Computing log-likelihood\n",
      "Iter 0021 Log-likely: x =   -12055.6, w =      -27.0, tot =   -12082.7\n",
      "Iter 0022: Sampling z\n",
      "Iter 0022: Sampling y|r\n",
      "Iter 0022: Updating spatial params\n",
      "Iter 0022: Computing log-likelihood\n",
      "Iter 0022 Log-likely: x =   -12056.0, w =      -26.1, tot =   -12082.1\n",
      "Iter 0023: Sampling z\n",
      "Iter 0023: Sampling y|r\n",
      "Iter 0023: Updating spatial params\n",
      "Iter 0023: Computing log-likelihood\n",
      "Iter 0023 Log-likely: x =   -12092.9, w =      -25.9, tot =   -12118.8\n",
      "Iter 0024: Sampling z\n",
      "Iter 0024: Sampling y|r\n",
      "Iter 0024: Updating spatial params\n",
      "Iter 0024: Computing log-likelihood\n",
      "Iter 0024 Log-likely: x =   -12049.9, w =      -25.5, tot =   -12075.3\n",
      "Iter 0025: Sampling z\n",
      "Iter 0025: Sampling y|r\n",
      "Iter 0025: Updating spatial params\n",
      "Iter 0025: Computing log-likelihood\n",
      "Iter 0025 Log-likely: x =   -12106.7, w =      -32.6, tot =   -12139.3\n"
     ]
    }
   ],
   "source": [
    "model = Model(dataset, n_topics=2, n_regions=1, symmetric=False,\n",
    "              alpha=.1, beta=.01, gamma=.01, delta=1.0,\n",
    "              dobs=25, roi_size=50.0, seed_init=1)\n",
    "model.initialize()\n",
    "for i in range(25):\n",
    "    model.run_complete_iteration()\n",
    "model.save(join(out_dir, 'gclda_model.pkl'))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
